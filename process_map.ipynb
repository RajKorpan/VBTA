{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2b65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import heapq\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_maps_directory = r'C:\\Users\\owner\\Documents\\PhD\\TierLab\\VBTA - Original Commented\\MAPF_benchmark_maps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de6241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"COMPLETED - DONT RUN AGAIN\"\"\"\n",
    "def load_map_yaml(map_filename):\n",
    "    with open(map_filename, 'r') as f:\n",
    "        type = f.readline().strip() # type of map, not used\n",
    "        height_line = f.readline().strip() # height dimension\n",
    "        width_line = f.readline().strip() # width dimension\n",
    "        map_line = f.readline().strip() # deliniation line, not used\n",
    "\n",
    "        height = int(height_line.split()[1]) # just number dimensions\n",
    "        width = int(width_line.split()[1])\n",
    "\n",
    "        grid = []\n",
    "        obstacles = []\n",
    "        for _ in range(height):\n",
    "            row_data = f.readline().strip()\n",
    "            if len(row_data) != width:\n",
    "                raise ValueError(f\"Map file error: row length {len(row_data)} != width {width}\") # sanity check for malformed map files\n",
    "            \n",
    "            # periods and G's are traversable terrain, everything else will be unpassable, \n",
    "            # there are 5 types of unpassable terrains, water will be unpassable\n",
    "            # row = [0 if c == '.' or c == 'G' else 1 for c in row_data] \n",
    "            # 1 means blocked, 0 means free\n",
    "            row = []\n",
    "            for c in row_data:\n",
    "                if c in [\".\", \"G\"]:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(1)\n",
    "                    obstacles.append((len(grid) + 1, len(row)))\n",
    "            grid.append(row)\n",
    "        \n",
    "        map_dict = {\n",
    "            \"map\" : {\n",
    "                \"dimensions\" : [height, width],\n",
    "                \"obstacles\" : obstacles\n",
    "                # [(x, y) for (x, y) in c for c in grid if c == 1]\n",
    "            },\n",
    "        }\n",
    "    \n",
    "    return grid, map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1c4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TEST\"\"\"\n",
    "# map_file = r'C:\\Users\\owner\\Documents\\PhD\\TierLab\\VBTA - Original Commented\\MAPF_benchmark_maps\\arena.map'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TEST\"\"\"\n",
    "# grid, map_dict = load_map_yaml(map_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TEST\"\"\"\n",
    "# with open('data.yaml', 'w') as f:\n",
    "#     yaml.dump(map_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"COMPLETED\"\"\"\n",
    "# for filename in os.listdir(benchmark_maps_directory):\n",
    "#     f = os.path.join(benchmark_maps_directory, filename)\n",
    "#     if os.path.isfile(f):\n",
    "#         grid, map_dict = load_map_yaml(f)\n",
    "#         with open(filename + \".yaml\", 'w') as out:\n",
    "#             yaml.dump(map_dict, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29919e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"same as above without the dictionary because we need the grid representation\"\"\"\n",
    "def load_map(map_filename):\n",
    "    \"\"\"Function to load ascii maps from the MAPF benchmark .map files\"\"\"\n",
    "    with open(map_filename, 'r') as f:\n",
    "        _type = f.readline().strip() # Type octile or similar\n",
    "        height_line = f.readline().strip() # Height of map e.g. \"height 45\"\n",
    "        width_line = f.readline().strip() # Width of map e.g. \"width 52\"\n",
    "        map_line = f.readline().strip() # delinates start of map with line that says \"map\"\n",
    "\n",
    "        height = int(height_line.split()[1])\n",
    "        width = int(width_line.split()[1])\n",
    "\n",
    "        grid = []\n",
    "        for _ in range(height):\n",
    "            row_data = f.readline().strip()\n",
    "            if len(row_data) != width:\n",
    "                raise ValueError(f\"Map file error: row length {len(row_data)} != width {width}\") # sanity check for malformed map files\n",
    "            # periods and G's are traversable terrain, everything else will be unpassable, there are 5 types of unpassable terrains, water will be unpassable\n",
    "            # row = [0 if c == '.' or c == 'G' else 1 for c in row_data] \n",
    "            # 1 means blocked, 0 means free\n",
    "            row = []\n",
    "            for c in row_data:\n",
    "                if c in [\".\", 'G']:\n",
    "                    row.append(0)\n",
    "                else:\n",
    "                    row.append(1)\n",
    "            grid.append(row)\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a13efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_free_position(grid, occupied_positions, agents_to_add):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    - grid: 2D list of 0/1 cells representing the map free/obstacles\n",
    "    - occupied_positions: exisiting agent positions, places we want to consider\n",
    "      blocked when choosing a new position\n",
    "\n",
    "    Returns: a single (row, col) position for one agent,\n",
    "            randomly from free cells with value = 0 that are not occupied\n",
    "    \"\"\"\n",
    "    free_cells = []\n",
    "    # iterate thru entire grid and find the free cells, make a list of them for choosing from\n",
    "    for r in range(len(grid)):\n",
    "        for c in range(len(grid[0])):\n",
    "            if grid[r][c] == 0 and grid[r][c] not in occupied_positions:\n",
    "                free_cells.append((r, c))\n",
    "\n",
    "    if not free_cells:\n",
    "       raise ValueError(\"No free cells available to place a robot!\")\n",
    "    \n",
    "    # randomly sample without replacement\n",
    "    # 2 * agents to add so we pick a start and end position for each agent at the same time\n",
    "    chosen = random.sample(free_cells, 2 * agents_to_add) \n",
    "\n",
    "    return chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ee01af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_random_map(directory, number_of_maps):\n",
    "    if not os.path.isdir:\n",
    "        return None\n",
    "    \n",
    "    maps = os.listdir(directory)\n",
    "    if not maps:\n",
    "        return None\n",
    "    \n",
    "    random_maps = random.sample(maps, number_of_maps)\n",
    "    return random_maps\n",
    "# use os.path.join(directory, map) for each map in random_maps to get full path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f98bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DONE\"\"\"\n",
    "# random_maps = pick_random_map(benchmark_maps_directory, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196a045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['den203d.map',\n",
       " 'den308d.map',\n",
       " 'lak505d.map',\n",
       " 'lak405d.map',\n",
       " 'orz103d.map',\n",
       " 'den504d.map',\n",
       " 'den011d.map',\n",
       " 'lak308d.map',\n",
       " 'orz000d.map',\n",
       " 'lak201d.map',\n",
       " 'lak515d.map',\n",
       " 'oth000d.map',\n",
       " 'brc501d.map',\n",
       " 'lak109d.map',\n",
       " 'brc203d.map',\n",
       " 'den200n.map',\n",
       " 'den001d.map',\n",
       " 'den400d.map',\n",
       " 'den407d.map',\n",
       " 'den998d.map',\n",
       " 'den200d.map',\n",
       " 'den500d.map',\n",
       " 'orz800d.map',\n",
       " 'lak401d.map',\n",
       " 'orz107d.map',\n",
       " 'lak519d.map',\n",
       " 'den000d.map',\n",
       " 'orz700d.map',\n",
       " 'den206d.map',\n",
       " 'den602d.map',\n",
       " 'ost000t.map',\n",
       " 'lak513d.map',\n",
       " 'den020d.map',\n",
       " 'orz100d.map',\n",
       " 'den600d.map',\n",
       " 'orz303d.map',\n",
       " 'orz703d.map',\n",
       " 'lak404d.map',\n",
       " 'brc505d.map',\n",
       " 'orz102d.map']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"DONE\"\"\"\n",
    "# random_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ffab033",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = r'C:\\Users\\owner\\Documents\\PhD\\TierLab\\VBTA - Original Commented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be2104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DONE\"\"\"\n",
    "# random_map_dict = {\n",
    "#     \"map_base_directory\" : base_directory,\n",
    "#     \"map_files\" : random_maps,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7775fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map_base_directory': 'C:\\\\Users\\\\owner\\\\Documents\\\\PhD\\\\TierLab\\\\VBTA - Original Commented',\n",
       " 'map_files': ['den203d.map',\n",
       "  'den308d.map',\n",
       "  'lak505d.map',\n",
       "  'lak405d.map',\n",
       "  'orz103d.map',\n",
       "  'den504d.map',\n",
       "  'den011d.map',\n",
       "  'lak308d.map',\n",
       "  'orz000d.map',\n",
       "  'lak201d.map',\n",
       "  'lak515d.map',\n",
       "  'oth000d.map',\n",
       "  'brc501d.map',\n",
       "  'lak109d.map',\n",
       "  'brc203d.map',\n",
       "  'den200n.map',\n",
       "  'den001d.map',\n",
       "  'den400d.map',\n",
       "  'den407d.map',\n",
       "  'den998d.map',\n",
       "  'den200d.map',\n",
       "  'den500d.map',\n",
       "  'orz800d.map',\n",
       "  'lak401d.map',\n",
       "  'orz107d.map',\n",
       "  'lak519d.map',\n",
       "  'den000d.map',\n",
       "  'orz700d.map',\n",
       "  'den206d.map',\n",
       "  'den602d.map',\n",
       "  'ost000t.map',\n",
       "  'lak513d.map',\n",
       "  'den020d.map',\n",
       "  'orz100d.map',\n",
       "  'den600d.map',\n",
       "  'orz303d.map',\n",
       "  'orz703d.map',\n",
       "  'lak404d.map',\n",
       "  'brc505d.map',\n",
       "  'orz102d.map']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"DONE\"\"\"\n",
    "# random_map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DONE\"\"\"\n",
    "# with open('random_maps.yaml', 'w') as f:\n",
    "#     yaml.dump(random_map_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_maps.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "base_dir = config['map_base_directory']\n",
    "map_filenames = config['map_files']\n",
    "\n",
    "full_map_paths = [os.path.join(base_dir, fname) for fname in map_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94226909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\owner\\Documents\\PhD\\TierLab\\VBTA - Original Commented\\den203d.map\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(full_map_paths[0])\n",
    "print(type(full_map_paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each map\n",
    "# get the random free positions for 10 - 100 agents by 10's \n",
    "    # this involves getting a start and goal position for each agent\n",
    "# then store these locations with the agent name (such as agent0, agent1, etc.) in a yaml file\n",
    "# THEN ill need to add a copy of the map information to each of those yaml files from the Processed_Benchmarks directory\n",
    "\n",
    "\n",
    "\"\"\"I THINK it might be the case we load each of the 40 maps into a pytorch geometric data object directly using either the \n",
    ".map file or the list of obstacles that I have for each map. Since these graphs are all fully connected, I just need to create\n",
    "a data object with all the nodes, making sure all obstacles are represented.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ec6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "053799f4",
   "metadata": {},
   "source": [
    "# PLAN\n",
    "\n",
    "### MISC\n",
    "- [X] migrate working CBS and visualization over\n",
    "- [X] check for functionality\n",
    "- [ ] decide on how to calculate difficulty metric (multi-output regression, use each predicted metric for its own statistic, like cost means this, makespan means that, etc, with one overall equally weighted normalized linear combination of the metrics (not predicted, just computed after))\n",
    "\n",
    "### DATA STRUCTURE\n",
    "- [X] all that is in the output is a cost for the solution and a schedule for each agent saying where they should be at each timestep\n",
    "- [X] add to output makespan, high level nodes expanded (constraint tree size), total conflicts identified\n",
    "- [X] graph data must be represented somehow (either adjacency matrix, or list of edges)\n",
    "    - [X] after researching ways to represent graphs it appears that the most computationally inexpensive way is using a list of edges (O(E)) instead of an adjacency matrix (up to O(V<sup>2</sup>))\n",
    "\n",
    "### PROCESSING MAPS\n",
    "- [X] pick the 40 maps we will be using randomly (pick_random_map)\n",
    "- [ ] need to process the maps further and create yaml files with an edge index, node positions (coordinates?), and node features (x_base = is_free, is_obstacle, is_start_node, is_goal_node) (maps fully connected in 4 DIRECTIONS ONLY NOT 8 breaks cbs)\n",
    "- [ ] optional instance specific features (number of agents, average manhattan distance between every start/goal pair, KEEP IT SIMPLE TO START IF IT WORKS TRY ADDING MORE, store as seperate tensor like data.u)\n",
    "    - [ ] save the static maps for re-use\n",
    "- [ ] generate CBS data by:\n",
    "    - [ ] get random start and goal positions for the chosen maps for a set of agents [10, 20, 30, ..., etc.] (load_map) (get_random_free_position)\n",
    "    - [ ] record each of the agent start and goal positions and agent name [agent0, agent1, ..., etc] in a dictionary called agents (loop get_random_free_position and make a dict for each map then write it in yaml)\n",
    "    - [ ] create new yaml files for each of the maps, for each count of agents [map1<sub>10</sub>agent.yaml, map1<sub>20</sub>agent.yaml, map1<sub>30</sub>agent.yaml, ..., etc] (for each of the chosen processed benchmark maps, repeat the two steps above 3 times for every amount from 10 - 100 agents going by 10's. we will take 3 of each example to ensure an average performace)\n",
    "    - [ ] now we have completed yaml files that should be solvable by the new CBS code, run CBS on each of the maps\n",
    "- [ ] take the input, output, and further processed yaml files with edge lists, and create the torch_geometric.data.Data object\n",
    "    - [ ] data.x is input, data.edge_index, data.pos, data.u, data.y is the targets (all 4) \n",
    "- [ ] predict all metrics with multi-output regression GNN, need to normalize target metrics first \n",
    "\n",
    "### LEARNING\n",
    "- [ ] Need 3 models, \n",
    "    - [ ] one for a graph level regression task to give us a difficulty metric to compare graphs against each other\n",
    "    - [ ] one for a node level prediction, maybe classification, maybe regression, some sort of difficulty metric per node? perhaps regression all the way to get continuous results instead of binary\n",
    "    - [ ] one for edge level prediction, again regression, again difficulty of edges (optional depending on the amount of work)\n",
    "- [ ] the node and edge level predictions should give us the potential to make a heatmap overlay (optional depending on the amount of work)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ec5b5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf8d5954",
   "metadata": {},
   "source": [
    "- [XXX] LLM based suitability rating\n",
    "    - one function call that takes in both profile and task description and gives us a suitability number to vote on\n",
    "        - prompt engineering\n",
    "- [X] Natural language description of task and robot (unstructured, natural language) / replace random robot and task generator (still structured, dictionary)\n",
    "    - LLM takes in natural language prompt (or character sheet), and make the dictionary from that, tasks too\n",
    "- [X] LLM directly assign robots to tasks : feed in descriptions and tasks and see what comes out (replace voting completely with LLM)\n",
    "    - compare to hybrid voting approach\n",
    "    - great comparison works or not\n",
    "- Replace CBS with LLM\n",
    "    - give LLM map, start and goal, and tell it to plan\n",
    "    - how to do conflict resolution when LLM gets it wrong\n",
    "    - \n",
    "\n",
    "# HIGH LEVEL PLAN\n",
    "- [ ] Full debug\n",
    "- [ ] LLM integration\n",
    "- [ ] run data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42b1543",
   "metadata": {},
   "source": [
    "# Empirical Hardness spin off\n",
    "    - re-process maps in a way that they are solvable by an LLM\n",
    "    - change the way they are represented\n",
    "    - get a plan from the LLM (an actual path for each agent)\n",
    "## HARD PART\n",
    "    - check for the plan correctness (brute force (fastest))\n",
    "    - step through each path and check for edge or node conflicts\n",
    "    - basically make CBS with an LLM\n",
    "    - ask the LLM to resolve the conflict\n",
    "    - Ill find the conflicts and the LLM will be asked to resolve and output a new plan\n",
    "\n",
    "\n",
    "- present both project plans and see what she accepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccca30f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
